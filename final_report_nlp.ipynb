{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Programming Languages using NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executive Summary\n",
    "\n",
    "- Our goal is to create a classification model to predict programming languages using Readme content from GitHub repositories.\n",
    "    - This can assist users in finding relevant content based on their programming language critera.\n",
    "    \n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- Most common programming language found in our dataset is Javascript followed by Python\n",
    "- Some of the most common words in Readmes were found to be: 'file', 'end', 'class','use' and 'object'.\n",
    "- The length of the readme's varies by programming languages.\n",
    "- \n",
    "- Our best model used  to predict programming languages with % accuracy. This model outperformed my baseline score of % accuracy, so it has value.\n",
    "\n",
    "### Project Overview\n",
    "\n",
    "- Trello board used to identify the different tasks for this project. You can find the board <a href=\"https://trello.com/b/PddXdOTJ/nlp-project\">here</a>\n",
    "- Python scripts were used to acquire, prepare and explore the data\n",
    "- \n",
    "- Statistical analyses tested the following hypotheses:\n",
    "    1. \n",
    " \n",
    "### Data Dictionary\n",
    "\n",
    "The data dictionary detailing all variables utilized in this analyses can be found <a href=\"https://github.com/mariam-and-cindy/predicting-programming-languages/blob/main/README.md\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required imports\n",
    "\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "\n",
    "import prepare as pr\n",
    "import unicodedata\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire Data\n",
    "\n",
    "Our data was scraped from 400 GitHub repositories. We decided to use the list of most forked repos on GitHub <a href=\"https://github.com/search?o=desc&p={i}&q=stars%3A%3E1&s=forks&type=Repositories\">here</a> for our dataset. \n",
    "\n",
    "This list of repositories was cached as a csv after acquisition and using our acquire script we pulled the username and title, language and readme contents of every repository into a json file. We converted the json file to a csv and will read that into a pandas dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the json file as df\n",
    "repo_json_file = 'data2.json'\n",
    "df = pd.read_json(repo_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to csv\n",
    "df.to_csv('git_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('git_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jtleek/datasharing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How to share data with a statistician\\n=======...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rdpeng/ProgrammingAssignment2</td>\n",
       "      <td>R</td>\n",
       "      <td>### Introduction\\n\\nThis second programming as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>octocat/Spoon-Knife</td>\n",
       "      <td>HTML</td>\n",
       "      <td>### Well hello there!\\n\\nThis repository is me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensorflow/tensorflow</td>\n",
       "      <td>C++</td>\n",
       "      <td>&lt;div align=\"center\"&gt;\\n  &lt;img src=\"https://www....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SmartThingsCommunity/SmartThingsPublic</td>\n",
       "      <td>Groovy</td>\n",
       "      <td># SmartThings Public GitHub Repo\\n\\nAn officia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     repo language  \\\n",
       "0                      jtleek/datasharing      NaN   \n",
       "1           rdpeng/ProgrammingAssignment2        R   \n",
       "2                     octocat/Spoon-Knife     HTML   \n",
       "3                   tensorflow/tensorflow      C++   \n",
       "4  SmartThingsCommunity/SmartThingsPublic   Groovy   \n",
       "\n",
       "                                     readme_contents  \n",
       "0  How to share data with a statistician\\n=======...  \n",
       "1  ### Introduction\\n\\nThis second programming as...  \n",
       "2  ### Well hello there!\\n\\nThis repository is me...  \n",
       "3  <div align=\"center\">\\n  <img src=\"https://www....  \n",
       "4  # SmartThings Public GitHub Repo\\n\\nAn officia...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick look at df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 400 entries, 0 to 399\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   repo             400 non-null    object\n",
      " 1   language         344 non-null    object\n",
      " 2   readme_contents  400 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 12.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# check for missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "- The dataset has 400 scraped repositories \n",
    "- Some Repositories are missing the language\n",
    "    - This could be because no primary programming language was obvious\n",
    "    - We will drop these rows during data preparation\n",
    "- All variables are object dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data\n",
    "\n",
    "During this stage of the pipeline, we will work on cleaning and preparing the data for exploration and modeling. The prepration functions are part of the prepare script which will be imported. \n",
    "\n",
    "The following steps will be performed to create the best performing model:\n",
    "- cleaning content to remove any special characters and certain words\n",
    "- removing stop words\n",
    "- lemmatizing content\n",
    "- stemming content\n",
    "- removing repos that have non English content\n",
    "- dropping rows with missing values\n",
    "- creating new columns\n",
    "    - cleaned\n",
    "    - stemmed\n",
    "    - lemmatized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '互联网 Java 工程师进阶知识完全扫盲'\n",
    "lang = TextBlob(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean (string):\n",
    "    '''\n",
    "    takes in a string and lowercase everything, normalize unicode characters, replace anything that is not a letter,\n",
    "    number, whitespace or a single quote.\n",
    "    retunr a clean string\n",
    "    '''\n",
    "    \n",
    "    string = string.lower()\n",
    "    string = unicodedata.normalize('NFKC',string)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8')\n",
    "    string = re.sub(r\"[^a-z0-9\\s]\", '', string)\n",
    "    string = re.sub(r'\\w*http\\w*', '', string)\n",
    "    string = re.sub(r'\\w*github\\w*', '', string)\n",
    "    string = re.sub(r'\\w*html\\w*', '', string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nonenglish (df):\n",
    "    '''\n",
    "    takes in df and 1 column to check if the text is in englis if not that row is going to be remove\n",
    "    '''\n",
    "    for n in range (0, len(df)):\n",
    "        basic_clean(df.readme_contents[n])\n",
    "        text = df.readme_contents[n]\n",
    "        lang = TextBlob(text)\n",
    "        if lang.detect_language() != 'en':\n",
    "            df =df.drop([n])\n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "not English 16\n",
      "17\n",
      "18\n",
      "19\n",
      "not English 19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "not English 37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "not English 43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "not English 76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "not English 90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "not English 108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "not English 115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "not English 124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "not English 131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "not English 135\n",
      "136\n",
      "137\n",
      "138\n",
      "not English 138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "not English 143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "not English 151\n",
      "152\n",
      "not English 152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "not English 156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "not English 166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "not English 171\n",
      "172\n",
      "173\n",
      "174\n",
      "not English 174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "not English 185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "not English 193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "not English 197\n",
      "198\n",
      "199\n",
      "not English 199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "not English 205\n",
      "206\n",
      "207\n",
      "208\n",
      "not English 208\n",
      "209\n",
      "210\n",
      "211\n",
      "not English 211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "not English 216\n",
      "217\n",
      "not English 217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "not English 221\n",
      "222\n",
      "223\n",
      "224\n",
      "not English 224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "not English 229\n",
      "230\n",
      "not English 230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "not English 239\n",
      "240\n",
      "241\n",
      "not English 241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "not English 248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "not English 273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "not English 277\n",
      "278\n",
      "not English 278\n",
      "279\n",
      "not English 279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "not English 292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "not English 298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "not English 310\n",
      "311\n",
      "not English 311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "not English 316\n",
      "317\n",
      "not English 317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "not English 324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "not English 328\n",
      "329\n",
      "not English 329\n",
      "330\n",
      "not English 330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "not English 336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "not English 341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "not English 352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "not English 357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "not English 365\n",
      "366\n",
      "not English 366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "not English 372\n",
      "373\n",
      "374\n",
      "not English 374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "not English 379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "not English 385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "not English 390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "not English 399\n"
     ]
    }
   ],
   "source": [
    "for n in range (0, len(df)):\n",
    "        text = df.readme_contents[n]\n",
    "        lang = TextBlob(text)\n",
    "        print(n)\n",
    "        if lang.detect_language() != 'en':\n",
    "            print('not English', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>PHPMailer/PHPMailer</td>\n",
       "      <td>PHP</td>\n",
       "      <td>![PHPMailer](https://raw.github.com/PHPMailer/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>education/GitHubGraduation-2021</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>## Updates\\n\\n### May 27, 2021\\nAnd that’s a w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>MarlinFirmware/Marlin</td>\n",
       "      <td>C++</td>\n",
       "      <td># Marlin 3D Printer Firmware\\n\\n![GitHub](http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>PanJiaChen/vue-element-admin</td>\n",
       "      <td>Vue</td>\n",
       "      <td>&lt;p align=\"center\"&gt;\\n  &lt;img width=\"320\" src=\"ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Homebrew/homebrew-core</td>\n",
       "      <td>Ruby</td>\n",
       "      <td># Homebrew Core\\n\\nCore formulae for the Homeb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>pytorch/examples</td>\n",
       "      <td>Python</td>\n",
       "      <td># PyTorch Examples\\n![Run Examples](https://gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>doocs/advanced-java</td>\n",
       "      <td>Java</td>\n",
       "      <td># 互联网 Java 工程师进阶知识完全扫盲\\n\\n[![stars](https://im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>vnpy/vnpy</td>\n",
       "      <td>C++</td>\n",
       "      <td># By Traders, For Traders.\\n\\n&lt;p align=\"center...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>springframeworkguru/spring5webapp</td>\n",
       "      <td>Java</td>\n",
       "      <td># Spring Framework 5: Beginner to Guru\\n\\nThis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>ArduPilot/ardupilot</td>\n",
       "      <td>C++</td>\n",
       "      <td># ArduPilot Project\\n\\n&lt;a href=\"https://ardupi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  repo    language  \\\n",
       "220                PHPMailer/PHPMailer         PHP   \n",
       "253    education/GitHubGraduation-2021  JavaScript   \n",
       "106              MarlinFirmware/Marlin         C++   \n",
       "39        PanJiaChen/vue-element-admin         Vue   \n",
       "196             Homebrew/homebrew-core        Ruby   \n",
       "..                                 ...         ...   \n",
       "287                   pytorch/examples      Python   \n",
       "101                doocs/advanced-java        Java   \n",
       "390                          vnpy/vnpy         C++   \n",
       "192  springframeworkguru/spring5webapp        Java   \n",
       "140                ArduPilot/ardupilot         C++   \n",
       "\n",
       "                                       readme_contents  \n",
       "220  ![PHPMailer](https://raw.github.com/PHPMailer/...  \n",
       "253  ## Updates\\n\\n### May 27, 2021\\nAnd that’s a w...  \n",
       "106  # Marlin 3D Printer Firmware\\n\\n![GitHub](http...  \n",
       "39   <p align=\"center\">\\n  <img width=\"320\" src=\"ht...  \n",
       "196  # Homebrew Core\\n\\nCore formulae for the Homeb...  \n",
       "..                                                 ...  \n",
       "287  # PyTorch Examples\\n![Run Examples](https://gi...  \n",
       "101  # 互联网 Java 工程师进阶知识完全扫盲\\n\\n[![stars](https://im...  \n",
       "390  # By Traders, For Traders.\\n\\n<p align=\"center...  \n",
       "192  # Spring Framework 5: Beginner to Guru\\n\\nThis...  \n",
       "140  # ArduPilot Project\\n\\n<a href=\"https://ardupi...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df.readme_contents[n]\n",
    "lang = TextBlob(text)\n",
    "if lang.detect_language() != 'en':\n",
    "    194             df =df.drop([n])\n",
    "    195     return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Data\n",
    "\n",
    "We used our train split to explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
